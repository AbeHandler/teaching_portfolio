{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The softmax function\n",
    "\n",
    "\n",
    "The softmax function can be written as follows, where $i$ indexes an instance in a dataset and there are $K$ output classes. \n",
    "\n",
    "$p(y_i = k | x_i) = \\frac{\\text{exp}(\\text{score}_{i, k})}{\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime}})} $\n",
    "\n",
    "In this notebook we will implement the softmax function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Thinking through the dimensions of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "K = 3   # let K be the number of classes\n",
    "J = 2   # let J be the number of features\n",
    "\n",
    "W = np.random.rand(K, J)  \n",
    "\n",
    "x_i = None\n",
    "\n",
    "scores = None  # scores should be a 1D vector of raw scores, one for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Plotting the exp function\n",
    "\n",
    "- Plot the exp function from -3 to 3. \n",
    "\n",
    "- What happens to the domain as the range gets very big or small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Naive softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sofmax(scores):\n",
    "    '''\n",
    "    Write a \"naive\" version of softmax that does not use vectorized operations\n",
    "    This will be *way* slower than the numpy version, but that is OK\n",
    "    We are just building intuition before jumping to the vectorized version\n",
    "    When you don't know how to code something in ML, it can be good to start with a \n",
    "    simple version using loops before skipping ahead to the vectorized version\n",
    "    '''\n",
    "    numerator = None\n",
    "    denominator = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Vectorized code (aside)\n",
    "\n",
    "Vectorized operations are much faster. A vectorized operation uses linear algebra packages like numpy to do computation very quickly using highly optimized code. Some implementations also implement vector operations in parallel.\n",
    "\n",
    "Let's experiment with vectorized versions of a simple function summing a list of numbers, before moving on to a vectorized softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def L2norm_no_vector(x):\n",
    "    '''\n",
    "    Your code here should not use vector operations\n",
    "    \n",
    "    input: a vector\n",
    "    output, L2 norm of x, \\sqrt{\\Sigma x_i^2}\n",
    "    '''\n",
    "    return 42\n",
    "        \n",
    "def L2norm_with_vectors(x):\n",
    "    '''\n",
    "    Your code here should use vector operations\n",
    "\n",
    "    input: a vector\n",
    "    output, L2 norm of x, \\sqrt{\\Sigma x_i^2}\n",
    "    '''\n",
    "    return 42\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going on, let's confirm that both implementations return the same outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2norm_no_vector([2,3,4]),  L2norm_with_vectors(np.asarray([2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test how long it takes our code to run as the list grows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "results = []\n",
    "\n",
    "for n in range(1, 10000, 1000):\n",
    "    runs = []\n",
    "    for i in range(25): # take an average of 25 runs\n",
    "        start = timer()\n",
    "        L2norm_no_vector(np.random.rand(n))\n",
    "        end = timer()\n",
    "        runs.append(end - start)\n",
    "    mean = np.mean(runs)\n",
    "    results.append({\"N\": n, \"f\": 'L2norm_no_vector', \"time\": mean})\n",
    "    \n",
    "for n in range(1, 10000, 1000):\n",
    "    runs = []\n",
    "    for i in range(25): # take an average of 25 runs\n",
    "        start = timer()\n",
    "        L2norm_with_vectors(np.random.rand(n))\n",
    "        end = timer()\n",
    "        runs.append(end - start)\n",
    "    mean = np.mean(runs)\n",
    "    results.append({\"N\": n, \"f\": 'L2norm_with_vectors', \"time\": mean})\n",
    " \n",
    "results = pd.DataFrame(results)\n",
    "alt.Chart(results).mark_line().encode(\n",
    "    x=\"N\",\n",
    "    y=\"time\",\n",
    "    color=\"f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized softmax\n",
    "\n",
    "Now we are ready to take our first crack at a vectorized softmax function. Remember the equation for the softmax is as follows:\n",
    "\n",
    "$p(y_i = k | x_i) = \\frac{\\text{exp}(\\text{score}_{i, k})}{\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime}})} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(scores):\n",
    "    '''\n",
    "    input: \n",
    "        a scores function, of $K$ real values between -\\inf and \\inf\n",
    "        \n",
    "    output:\n",
    "        a vector of probabilities that sums to 1\n",
    "    '''\n",
    "    return 42\n",
    "\n",
    "softmax([1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax questions\n",
    "\n",
    "1. What happens when the scores are the same?\n",
    "2. What happens when one score is bigger than the others\n",
    "3. Why do you think this function might be called a \"soft\" max?\n",
    "4. What happens if you pass in the scores `[10000, 1]`\n",
    "4. What happens if you pass in the scores `[0, 1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerically stable softmax \n",
    "\n",
    "\n",
    "$p(y_i = k | x_i) = \\frac{\\text{exp}(\\text{score}_{i, k})}{\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime}})}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some max score function $c$ in the vector of score functions. We can always divide the numerator and denominator of a fraction by $c$. It will affect the value of the numerator and denominator but not the ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(y_i = k | x_i) = \\frac{\\text{exp}(\\text{score}_{i, k}) / e^c}{\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime}})/ e^c}$\n",
    "\n",
    "$p(y_i = k | x_i) = \\frac{\\text{exp}(\\text{score}_{i, k}) exp(-c)}{\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime}}) exp(-c)}$\n",
    "\n",
    "$p(y_i = k | x_i) = \\frac{\\text{exp}(\\text{score}_{i, k} - c) }{\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime} } -c ) }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3/2)/(9/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(y_i = k | x_i) = \\frac{\\text{exp}(\\text{score}_{i, k} - c)}{\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime}}  - c)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.26894142, 0.73105858]), array([0.26894142, 0.73105858]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_c(scores, c):\n",
    "    '''\n",
    "    input: \n",
    "        a scores function, of $K$ real values between -\\inf and \\inf\n",
    "        \n",
    "    output:\n",
    "        a vector of probabilities that sums to 1\n",
    "    '''\n",
    "    return np.exp(scores - c)/np.sum(np.exp(scores - c))\n",
    "\n",
    "softmax(np.asarray([1,2])),  softmax_c(np.asarray([1,2]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's take the log of the softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(y_i = k | x_i) = \\frac{\\text{exp}(\\text{score}_{i, k} - c)}{\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime}}  - c)}$\n",
    "\n",
    "$ log p(y_i = k | x_i) = log (\\text{score}_{i, k}) - c  - log {\\sum_{k'}^K \\text{exp}(\\text{score}_{i,{k^\\prime}}  - c)}$\n",
    "\n",
    "We can use any $c$ we want so let's set it to the largest item in our scores vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.739274941520501e+18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_softmax(scores):\n",
    "    '''\n",
    "    input: \n",
    "        a scores function, of $K$ real values between -\\inf and \\inf\n",
    "        \n",
    "    output:\n",
    "        a vector of probabilities that sums to 1\n",
    "    '''\n",
    "    return 42\n",
    "\n",
    "\n",
    "np.exp(log_softmax([10000, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
